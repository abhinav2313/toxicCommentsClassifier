{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhsharm/anaconda/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.text as kpt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train = pd.read_csv(\"train.csv\")\n",
    "raw_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "y = raw_train[labels]\n",
    "y=y.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "X = raw_train['comment_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicksteinhauser/anaconda/envs/py36/lib/python3.6/site-packages/keras/preprocessing/text.py:157: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/36700790/keras-text-classification-lstm-how-to-input-text\n",
    "\n",
    "X[0] = raw_train['comment_text']\n",
    "\n",
    "#makes list of words in bag-of-all-words-in-dataset for numerical of \n",
    "tk = keras.preprocessing.text.Tokenizer(nb_words=2000, lower=True, split=\" \")\n",
    "tk.fit_on_texts(X[0]) #finds all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tk.texts_to_sequences(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('caustic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# schema necessary for label columns to be ints for vectorization later\n",
    "start_data = spark.read.csv(\"train.csv\", header = \"true\", schema = \"id STRING, comment_text STRING, toxic INT, severe_toxic INT, obscene INT,threat INT,insult INT,identity_hate INT\")\n",
    "start_data = start_data.na.drop() # label columns have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length\n",
    "data = start_data.withColumn('length', length(start_data['comment_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
    "\n",
    "# Create all the features to the data set\n",
    "tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"token_text\") #can cut down on columns\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
    "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector\n",
    "\n",
    "# Create feature vectors\n",
    "clean_up_features = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')\n",
    "clean_up_labels = VectorAssembler(inputCols=labels, outputCol='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a and run a data processing Pipeline\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipeline = Pipeline(stages=[ tokenizer, stopremove, hashingTF, idf, clean_up_features, clean_up_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipeline.fit(data)\n",
    "cleaned = cleaner.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              labels|            features|\n",
      "+--------------------+--------------------+\n",
      "|           (6,[],[])|(262145,[19208,24...|\n",
      "|           (6,[],[])|(262145,[17429,38...|\n",
      "|           (6,[],[])|(262145,[14,9639,...|\n",
      "|           (6,[],[])|(262145,[37852,39...|\n",
      "|           (6,[],[])|(262145,[44501,72...|\n",
      "|[1.0,1.0,1.0,0.0,...|(262145,[25551,34...|\n",
      "|           (6,[],[])|(262145,[37470,55...|\n",
      "|           (6,[],[])|(262145,[5147,523...|\n",
      "|           (6,[],[])|(262145,[9639,916...|\n",
      "|           (6,[],[])|(262145,[13781,21...|\n",
      "|       (6,[0],[1.0])|(262145,[9639,122...|\n",
      "|           (6,[],[])|(262145,[70503,87...|\n",
      "|           (6,[],[])|(262145,[29238,45...|\n",
      "|           (6,[],[])|(262145,[15889,19...|\n",
      "|           (6,[],[])|(262145,[14,9639,...|\n",
      "|           (6,[],[])|(262145,[56614,86...|\n",
      "|           (6,[],[])|(262145,[4649,158...|\n",
      "|           (6,[],[])|(262145,[9639,112...|\n",
      "|           (6,[],[])|(262145,[24417,25...|\n",
      "|           (6,[],[])|(262145,[5377,963...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show label of and resulting features\n",
    "\n",
    "cleaned.select(['labels', 'features']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=\"Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms\", comment_text=' just closure on some GAs after I voted at New York Dolls FAC. And please don\\'t remove the template from the talk page since I\\'m retired now.89.205.38.27\"', toxic=0, severe_toxic=0, obscene=0, threat=0, insult=0, identity_hate=0, length=154, token_text=['', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'voted', 'at', 'new', 'york', 'dolls', 'fac.', 'and', 'please', \"don't\", 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', \"i'm\", 'retired', 'now.89.205.38.27\"'], stop_tokens=['', 'closure', 'gas', 'voted', 'new', 'york', 'dolls', 'fac.', 'please', 'remove', 'template', 'talk', 'page', 'since', 'retired', 'now.89.205.38.27\"'], hash_token=SparseVector(262144, {19208: 1.0, 24417: 1.0, 25000: 1.0, 29945: 1.0, 46075: 1.0, 59853: 1.0, 72125: 1.0, 82999: 1.0, 83922: 1.0, 91677: 1.0, 97171: 1.0, 100258: 1.0, 101169: 1.0, 103838: 2.0, 110427: 1.0, 113031: 1.0, 113418: 1.0, 135568: 1.0, 145284: 1.0, 169364: 1.0, 176964: 1.0, 192137: 1.0, 229137: 1.0, 230921: 1.0, 249180: 1.0, 249835: 1.0, 257516: 1.0}), idf_token=SparseVector(262144, {19208: 2.9418, 24417: 1.0001, 25000: 6.8433, 29945: 3.877, 46075: 7.583, 59853: 3.9599, 72125: 2.8969, 82999: 8.6816, 83922: 7.4705, 91677: 1.04, 97171: 2.4473, 100258: 1.746, 101169: 2.4029, 103838: 1.3353, 110427: 2.7469, 113031: 9.5289, 113418: 2.6604, 135568: 4.3013, 145284: 7.9884, 169364: 2.9101, 176964: 2.4015, 192137: 3.8004, 229137: 5.4098, 230921: 2.7065, 249180: 0.9432, 249835: 7.6831, 257516: 10.6275}), features=SparseVector(262145, {19208: 2.9418, 24417: 1.0001, 25000: 6.8433, 29945: 3.877, 46075: 7.583, 59853: 3.9599, 72125: 2.8969, 82999: 8.6816, 83922: 7.4705, 91677: 1.04, 97171: 2.4473, 100258: 1.746, 101169: 2.4029, 103838: 1.3353, 110427: 2.7469, 113031: 9.5289, 113418: 2.6604, 135568: 4.3013, 145284: 7.9884, 169364: 2.9101, 176964: 2.4015, 192137: 3.8004, 229137: 5.4098, 230921: 2.7065, 249180: 0.9432, 249835: 7.6831, 257516: 10.6275, 262144: 154.0}), labels=SparseVector(6, {})),\n",
       " Row(id='000103f0d9cfb60f', comment_text=\"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\", toxic=0, severe_toxic=0, obscene=0, threat=0, insult=0, identity_hate=0, length=112, token_text=[\"d'aww!\", 'he', 'matches', 'this', 'background', 'colour', \"i'm\", 'seemingly', 'stuck', 'with.', 'thanks.', '', '(talk)', '21:51,', 'january', '11,', '2016', '(utc)'], stop_tokens=[\"d'aww!\", 'matches', 'background', 'colour', 'seemingly', 'stuck', 'with.', 'thanks.', '', '(talk)', '21:51,', 'january', '11,', '2016', '(utc)'], hash_token=SparseVector(262144, {17429: 1.0, 38728: 1.0, 83815: 1.0, 88337: 1.0, 101527: 1.0, 101833: 1.0, 108541: 1.0, 125765: 1.0, 141219: 1.0, 151980: 1.0, 169364: 1.0, 169800: 1.0, 203235: 1.0, 208090: 1.0, 219140: 1.0, 242101: 1.0, 248135: 1.0, 249180: 1.0}), idf_token=SparseVector(262144, {17429: 9.9343, 38728: 8.3762, 83815: 7.0721, 88337: 4.2398, 101527: 4.2132, 101833: 6.4844, 108541: 1.667, 125765: 9.7112, 141219: 4.4801, 151980: 7.7371, 169364: 2.9101, 169800: 8.9227, 203235: 8.1851, 208090: 8.1426, 219140: 6.7563, 242101: 2.9857, 248135: 6.2517, 249180: 0.9432}), features=SparseVector(262145, {17429: 9.9343, 38728: 8.3762, 83815: 7.0721, 88337: 4.2398, 101527: 4.2132, 101833: 6.4844, 108541: 1.667, 125765: 9.7112, 141219: 4.4801, 151980: 7.7371, 169364: 2.9101, 169800: 8.9227, 203235: 8.1851, 208090: 8.1426, 219140: 6.7563, 242101: 2.9857, 248135: 6.2517, 249180: 0.9432, 262144: 112.0}), labels=SparseVector(6, {})),\n",
       " Row(id='000113f07ec002fd', comment_text=\"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\", toxic=0, severe_toxic=0, obscene=0, threat=0, insult=0, identity_hate=0, length=233, token_text=['hey', 'man,', \"i'm\", 'really', 'not', 'trying', 'to', 'edit', 'war.', \"it's\", 'just', 'that', 'this', 'guy', 'is', 'constantly', 'removing', 'relevant', 'information', 'and', 'talking', 'to', 'me', 'through', 'edits', 'instead', 'of', 'my', 'talk', 'page.', 'he', 'seems', 'to', 'care', 'more', 'about', 'the', 'formatting', 'than', 'the', 'actual', 'info.'], stop_tokens=['hey', 'man,', 'really', 'trying', 'edit', 'war.', 'guy', 'constantly', 'removing', 'relevant', 'information', 'talking', 'edits', 'instead', 'talk', 'page.', 'seems', 'care', 'formatting', 'actual', 'info.'], hash_token=SparseVector(262144, {14: 1.0, 9639: 1.0, 15889: 1.0, 32630: 1.0, 37852: 1.0, 45885: 1.0, 48448: 1.0, 66130: 1.0, 70527: 1.0, 72125: 1.0, 74079: 1.0, 78714: 1.0, 91137: 1.0, 91677: 1.0, 95805: 1.0, 97171: 1.0, 103838: 2.0, 108541: 1.0, 109230: 1.0, 120739: 1.0, 136414: 1.0, 139098: 1.0, 158129: 1.0, 160141: 1.0, 162698: 1.0, 169364: 1.0, 181998: 1.0, 193290: 1.0, 205044: 3.0, 218965: 1.0, 221047: 1.0, 223970: 1.0, 234312: 1.0, 239029: 1.0, 241149: 1.0, 242101: 1.0, 244466: 1.0, 245378: 1.0, 247768: 1.0}), idf_token=SparseVector(262144, {14: 3.6516, 9639: 1.1717, 15889: 1.1926, 32630: 7.2263, 37852: 2.2023, 45885: 5.3392, 48448: 1.3626, 66130: 5.4946, 70527: 4.7681, 72125: 2.8969, 74079: 4.8845, 78714: 6.8663, 91137: 2.4278, 91677: 1.04, 95805: 2.924, 97171: 2.4473, 103838: 1.3353, 108541: 1.667, 109230: 4.9254, 120739: 5.1981, 136414: 6.8547, 139098: 1.6174, 158129: 4.0134, 160141: 3.2751, 162698: 3.4111, 169364: 2.9101, 181998: 5.0611, 193290: 3.7425, 205044: 2.5597, 218965: 4.1406, 221047: 2.608, 223970: 3.958, 234312: 4.9105, 239029: 2.7866, 241149: 6.3934, 242101: 2.9857, 244466: 3.9599, 245378: 6.8208, 247768: 4.9645}), features=SparseVector(262145, {14: 3.6516, 9639: 1.1717, 15889: 1.1926, 32630: 7.2263, 37852: 2.2023, 45885: 5.3392, 48448: 1.3626, 66130: 5.4946, 70527: 4.7681, 72125: 2.8969, 74079: 4.8845, 78714: 6.8663, 91137: 2.4278, 91677: 1.04, 95805: 2.924, 97171: 2.4473, 103838: 1.3353, 108541: 1.667, 109230: 4.9254, 120739: 5.1981, 136414: 6.8547, 139098: 1.6174, 158129: 4.0134, 160141: 3.2751, 162698: 3.4111, 169364: 2.9101, 181998: 5.0611, 193290: 3.7425, 205044: 2.5597, 218965: 4.1406, 221047: 2.608, 223970: 3.958, 234312: 4.9105, 239029: 2.7866, 241149: 6.3934, 242101: 2.9857, 244466: 3.9599, 245378: 6.8208, 247768: 4.9645, 262144: 233.0}), labels=SparseVector(6, {})),\n",
       " Row(id='0001d958c54c6e35', comment_text=\"You, sir, are my hero. Any chance you remember what page that's on?\", toxic=0, severe_toxic=0, obscene=0, threat=0, insult=0, identity_hate=0, length=67, token_text=['you,', 'sir,', 'are', 'my', 'hero.', 'any', 'chance', 'you', 'remember', 'what', 'page', \"that's\", 'on?'], stop_tokens=['you,', 'sir,', 'hero.', 'chance', 'remember', 'page', 'on?'], hash_token=SparseVector(262144, {37852: 1.0, 39081: 1.0, 74290: 1.0, 81566: 1.0, 104218: 1.0, 110427: 1.0, 126097: 1.0, 135499: 1.0, 154735: 1.0, 167122: 1.0, 196997: 1.0, 199416: 1.0, 252801: 1.0}), idf_token=SparseVector(262144, {37852: 2.2023, 39081: 3.8257, 74290: 5.9547, 81566: 2.4241, 104218: 8.7557, 110427: 2.7469, 126097: 7.5364, 135499: 2.806, 154735: 7.5594, 167122: 1.8819, 196997: 5.4235, 199416: 4.6335, 252801: 1.1504}), features=SparseVector(262145, {37852: 2.2023, 39081: 3.8257, 74290: 5.9547, 81566: 2.4241, 104218: 8.7557, 110427: 2.7469, 126097: 7.5364, 135499: 2.806, 154735: 7.5594, 167122: 1.8819, 196997: 5.4235, 199416: 4.6335, 252801: 1.1504, 262144: 67.0}), labels=SparseVector(6, {})),\n",
       " Row(id='Congratulations from me as well', comment_text=' use the tools well. \\xa0· talk \"\"\"', toxic=0, severe_toxic=0, obscene=0, threat=0, insult=0, identity_hate=0, length=32, token_text=['', 'use', 'the', 'tools', 'well.', '\\xa0·', 'talk', '\"\"\"'], stop_tokens=['', 'use', 'tools', 'well.', '\\xa0·', 'talk', '\"\"\"'], hash_token=SparseVector(262144, {44501: 1.0, 72125: 1.0, 103838: 1.0, 116873: 1.0, 123548: 1.0, 150611: 1.0, 249180: 1.0, 256018: 1.0}), idf_token=SparseVector(262144, {44501: 9.0181, 72125: 2.8969, 103838: 0.6677, 116873: 3.3534, 123548: 5.2361, 150611: 2.4538, 249180: 0.9432, 256018: 7.3503}), features=SparseVector(262145, {44501: 9.0181, 72125: 2.8969, 103838: 0.6677, 116873: 3.3534, 123548: 5.2361, 150611: 2.4538, 249180: 0.9432, 256018: 7.3503, 262144: 32.0}), labels=SparseVector(6, {})),\n",
       " Row(id='0002bcb3da6cb337', comment_text='COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK', toxic=1, severe_toxic=1, obscene=1, threat=0, insult=1, identity_hate=0, length=44, token_text=['cocksucker', 'before', 'you', 'piss', 'around', 'on', 'my', 'work'], stop_tokens=['cocksucker', 'piss', 'around', 'work'], hash_token=SparseVector(262144, {25551: 1.0, 34343: 1.0, 37852: 1.0, 49517: 1.0, 78329: 1.0, 100258: 1.0, 160893: 1.0, 252801: 1.0}), idf_token=SparseVector(262144, {25551: 3.92, 34343: 4.08, 37852: 2.2023, 49517: 6.9386, 78329: 4.6588, 100258: 1.746, 160893: 8.6126, 252801: 1.1504}), features=SparseVector(262145, {25551: 3.92, 34343: 4.08, 37852: 2.2023, 49517: 6.9386, 78329: 4.6588, 100258: 1.746, 160893: 8.6126, 252801: 1.1504, 262144: 44.0}), labels=DenseVector([1.0, 1.0, 1.0, 0.0, 1.0, 0.0])),\n",
       " Row(id='00031b1e95af7921', comment_text=\"Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.\", toxic=0, severe_toxic=0, obscene=0, threat=0, insult=0, identity_hate=0, length=115, token_text=['your', 'vandalism', 'to', 'the', 'matt', 'shirvington', 'article', 'has', 'been', 'reverted.', '', 'please', \"don't\", 'do', 'it', 'again,', 'or', 'you', 'will', 'be', 'banned.'], stop_tokens=['vandalism', 'matt', 'shirvington', 'article', 'reverted.', '', 'please', 'again,', 'banned.'], hash_token=SparseVector(262144, {37470: 1.0, 55039: 1.0, 66796: 1.0, 86175: 1.0, 89356: 1.0, 96524: 1.0, 103838: 1.0, 112908: 1.0, 113245: 1.0, 113418: 1.0, 113764: 1.0, 167152: 1.0, 167222: 1.0, 192029: 1.0, 205044: 1.0, 227431: 1.0, 230921: 1.0, 235520: 1.0, 247107: 1.0, 249180: 1.0, 252801: 1.0}), idf_token=SparseVector(262144, {37470: 2.3678, 55039: 2.0486, 66796: 6.4765, 86175: 1.4171, 89356: 2.4979, 96524: 7.7653, 103838: 0.6677, 112908: 4.9154, 113245: 10.6275, 113418: 2.6604, 113764: 2.659, 167152: 1.6772, 167222: 2.5403, 192029: 4.9803, 205044: 0.8532, 227431: 2.8184, 230921: 2.7065, 235520: 6.9139, 247107: 2.3085, 249180: 0.9432, 252801: 1.1504}), features=SparseVector(262145, {37470: 2.3678, 55039: 2.0486, 66796: 6.4765, 86175: 1.4171, 89356: 2.4979, 96524: 7.7653, 103838: 0.6677, 112908: 4.9154, 113245: 10.6275, 113418: 2.6604, 113764: 2.659, 167152: 1.6772, 167222: 2.5403, 192029: 4.9803, 205044: 0.8532, 227431: 2.8184, 230921: 2.7065, 235520: 6.9139, 247107: 2.3085, 249180: 0.9432, 252801: 1.1504, 262144: 115.0}), labels=SparseVector(6, {})),\n",
       " Row(id='00037261f536c51d', comment_text=\"Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169\", toxic=0, severe_toxic=0, obscene=0, threat=0, insult=0, identity_hate=0, length=472, token_text=['sorry', 'if', 'the', 'word', \"'nonsense'\", 'was', 'offensive', 'to', 'you.', 'anyway,', \"i'm\", 'not', 'intending', 'to', 'write', 'anything', 'in', 'the', 'article(wow', 'they', 'would', 'jump', 'on', 'me', 'for', 'vandalism),', \"i'm\", 'merely', 'requesting', 'that', 'it', 'be', 'more', 'encyclopedic', 'so', 'one', 'can', 'use', 'it', 'for', 'school', 'as', 'a', 'reference.', 'i', 'have', 'been', 'to', 'the', 'selective', 'breeding', 'page', 'but', \"it's\", 'almost', 'a', 'stub.', 'it', 'points', 'to', \"'animal\", \"breeding'\", 'which', 'is', 'a', 'short', 'messy', 'article', 'that', 'gives', 'you', 'no', 'info.', 'there', 'must', 'be', 'someone', 'around', 'with', 'expertise', 'in', 'eugenics?', '93.161.107.169'], stop_tokens=['sorry', 'word', \"'nonsense'\", 'offensive', 'you.', 'anyway,', 'intending', 'write', 'anything', 'article(wow', 'jump', 'vandalism),', 'merely', 'requesting', 'encyclopedic', 'one', 'use', 'school', 'reference.', 'selective', 'breeding', 'page', 'almost', 'stub.', 'points', \"'animal\", \"breeding'\", 'short', 'messy', 'article', 'gives', 'info.', 'must', 'someone', 'around', 'expertise', 'eugenics?', '93.161.107.169'], hash_token=SparseVector(262144, {5147: 1.0, 5232: 1.0, 7555: 1.0, 12861: 1.0, 15889: 1.0, 15945: 1.0, 16332: 2.0, 20787: 1.0, 20980: 1.0, 24031: 1.0, 24417: 1.0, 25570: 1.0, 36073: 1.0, 43265: 1.0, 46893: 1.0, 48448: 2.0, 50940: 1.0, 55242: 1.0, 55403: 1.0, 62655: 1.0, 63473: 1.0, 68867: 1.0, 77492: 1.0, 78329: 1.0, 80843: 1.0, 86175: 3.0, 91981: 1.0, 95805: 1.0, 100258: 1.0, 103838: 3.0, 107810: 1.0, 110427: 1.0, 116056: 1.0, 116873: 1.0, 118449: 1.0, 119550: 1.0, 125372: 1.0, 126466: 1.0, 136414: 1.0, 139098: 1.0, 139323: 1.0, 151536: 1.0, 156250: 1.0, 162752: 1.0, 163995: 1.0, 165924: 1.0, 167152: 2.0, 167222: 1.0, 169364: 2.0, 175541: 1.0, 180535: 1.0, 188424: 1.0, 189683: 1.0, 190347: 1.0, 191439: 1.0, 197219: 1.0, 205044: 4.0, 221047: 1.0, 222453: 2.0, 223821: 1.0, 227410: 3.0, 227431: 1.0, 229407: 1.0, 239029: 1.0, 246199: 1.0, 252801: 1.0, 253475: 1.0, 253534: 1.0, 257807: 1.0}), idf_token=SparseVector(262144, {5147: 10.222, 5232: 6.0476, 7555: 8.4874, 12861: 9.9343, 15889: 1.1926, 15945: 6.6293, 16332: 3.1597, 20787: 5.6681, 20980: 6.9768, 24031: 5.0572, 24417: 1.0001, 25570: 2.168, 36073: 2.4515, 43265: 10.222, 46893: 7.9194, 48448: 2.7252, 50940: 1.9571, 55242: 2.0399, 55403: 10.6275, 62655: 5.4542, 63473: 4.9237, 68867: 2.5425, 77492: 5.8526, 78329: 4.6588, 80843: 5.6966, 86175: 4.2512, 91981: 6.7988, 95805: 2.924, 100258: 1.746, 103838: 2.003, 107810: 4.1368, 110427: 2.7469, 116056: 4.4372, 116873: 3.3534, 118449: 7.9884, 119550: 7.2953, 125372: 2.7884, 126466: 2.0256, 136414: 6.8547, 139098: 1.6174, 139323: 9.9343, 151536: 2.8115, 156250: 2.624, 162752: 9.0181, 163995: 10.6275, 165924: 3.8047, 167152: 3.3544, 167222: 2.5403, 169364: 5.8203, 175541: 2.9838, 180535: 2.6325, 188424: 2.3992, 189683: 1.9945, 190347: 9.7112, 191439: 8.6816, 197219: 5.909, 205044: 3.4129, 221047: 2.608, 222453: 2.9004, 223821: 5.4373, 227410: 3.0975, 227431: 2.8184, 229407: 4.3574, 239029: 2.7866, 246199: 6.4608, 252801: 1.1504, 253475: 1.8078, 253534: 3.7737, 257807: 5.7222}), features=SparseVector(262145, {5147: 10.222, 5232: 6.0476, 7555: 8.4874, 12861: 9.9343, 15889: 1.1926, 15945: 6.6293, 16332: 3.1597, 20787: 5.6681, 20980: 6.9768, 24031: 5.0572, 24417: 1.0001, 25570: 2.168, 36073: 2.4515, 43265: 10.222, 46893: 7.9194, 48448: 2.7252, 50940: 1.9571, 55242: 2.0399, 55403: 10.6275, 62655: 5.4542, 63473: 4.9237, 68867: 2.5425, 77492: 5.8526, 78329: 4.6588, 80843: 5.6966, 86175: 4.2512, 91981: 6.7988, 95805: 2.924, 100258: 1.746, 103838: 2.003, 107810: 4.1368, 110427: 2.7469, 116056: 4.4372, 116873: 3.3534, 118449: 7.9884, 119550: 7.2953, 125372: 2.7884, 126466: 2.0256, 136414: 6.8547, 139098: 1.6174, 139323: 9.9343, 151536: 2.8115, 156250: 2.624, 162752: 9.0181, 163995: 10.6275, 165924: 3.8047, 167152: 3.3544, 167222: 2.5403, 169364: 5.8203, 175541: 2.9838, 180535: 2.6325, 188424: 2.3992, 189683: 1.9945, 190347: 9.7112, 191439: 8.6816, 197219: 5.909, 205044: 3.4129, 221047: 2.608, 222453: 2.9004, 223821: 5.4373, 227410: 3.0975, 227431: 2.8184, 229407: 4.3574, 239029: 2.7866, 246199: 6.4608, 252801: 1.1504, 253475: 1.8078, 253534: 3.7737, 257807: 5.7222, 262144: 472.0}), labels=SparseVector(6, {})),\n",
       " Row(id='00040093b2687caa', comment_text='alignment on this subject and which are contrary to those of DuLithgow', toxic=0, severe_toxic=0, obscene=0, threat=0, insult=0, identity_hate=0, length=70, token_text=['alignment', 'on', 'this', 'subject', 'and', 'which', 'are', 'contrary', 'to', 'those', 'of', 'dulithgow'], stop_tokens=['alignment', 'subject', 'contrary', 'dulithgow'], hash_token=SparseVector(262144, {9639: 1.0, 91677: 1.0, 99736: 1.0, 100258: 1.0, 102641: 1.0, 106847: 1.0, 108541: 1.0, 162813: 1.0, 167122: 1.0, 175541: 1.0, 193327: 1.0, 205044: 1.0}), idf_token=SparseVector(262144, {9639: 1.1717, 91677: 1.04, 99736: 3.8273, 100258: 1.746, 102641: 9.9343, 106847: 9.5289, 108541: 1.667, 162813: 5.102, 167122: 1.8819, 175541: 2.9838, 193327: 6.9899, 205044: 0.8532}), features=SparseVector(262145, {9639: 1.1717, 91677: 1.04, 99736: 3.8273, 100258: 1.746, 102641: 9.9343, 106847: 9.5289, 108541: 1.667, 162813: 5.102, 167122: 1.8819, 175541: 2.9838, 193327: 6.9899, 205044: 0.8532, 262144: 70.0}), labels=SparseVector(6, {})),\n",
       " Row(id='00070ef96486d6f9', comment_text=\"Oh, and the girl above started her arguments with me. She stuck her nose where it doesn't belong. I believe the argument was between me and Yvesnimmo. But like I said, the situation was settled and I apologized. Thanks,\", toxic=0, severe_toxic=0, obscene=0, threat=0, insult=0, identity_hate=0, length=219, token_text=['oh,', 'and', 'the', 'girl', 'above', 'started', 'her', 'arguments', 'with', 'me.', 'she', 'stuck', 'her', 'nose', 'where', 'it', \"doesn't\", 'belong.', 'i', 'believe', 'the', 'argument', 'was', 'between', 'me', 'and', 'yvesnimmo.', 'but', 'like', 'i', 'said,', 'the', 'situation', 'was', 'settled', 'and', 'i', 'apologized.', 'thanks,'], stop_tokens=['oh,', 'girl', 'started', 'arguments', 'me.', 'stuck', 'nose', 'belong.', 'believe', 'argument', 'yvesnimmo.', 'like', 'said,', 'situation', 'settled', 'apologized.', 'thanks,'], hash_token=SparseVector(262144, {13781: 1.0, 21471: 1.0, 22552: 1.0, 24417: 3.0, 25570: 2.0, 28511: 1.0, 36524: 1.0, 46299: 1.0, 56407: 1.0, 72268: 1.0, 83815: 1.0, 86175: 1.0, 91677: 3.0, 103838: 3.0, 118554: 1.0, 126466: 1.0, 141693: 1.0, 151496: 1.0, 156678: 1.0, 169961: 1.0, 172634: 1.0, 181500: 1.0, 184109: 1.0, 189683: 1.0, 206410: 2.0, 208258: 1.0, 215252: 1.0, 219056: 1.0, 219797: 1.0, 221047: 1.0, 227091: 1.0}), idf_token=SparseVector(262144, {13781: 6.8898, 21471: 4.6992, 22552: 5.2136, 24417: 3.0004, 25570: 4.3361, 28511: 7.7371, 36524: 5.5873, 46299: 3.7679, 56407: 4.0879, 72268: 6.8898, 83815: 7.0721, 86175: 1.4171, 91677: 3.12, 103838: 2.003, 118554: 4.1232, 126466: 2.0256, 141693: 5.6303, 151496: 3.9948, 156678: 6.0789, 169961: 4.7724, 172634: 4.6385, 181500: 5.8484, 184109: 7.6318, 189683: 1.9945, 206410: 9.1181, 208258: 2.5911, 215252: 9.7112, 219056: 5.9879, 219797: 8.3762, 221047: 2.608, 227091: 5.4627}), features=SparseVector(262145, {13781: 6.8898, 21471: 4.6992, 22552: 5.2136, 24417: 3.0004, 25570: 4.3361, 28511: 7.7371, 36524: 5.5873, 46299: 3.7679, 56407: 4.0879, 72268: 6.8898, 83815: 7.0721, 86175: 1.4171, 91677: 3.12, 103838: 2.003, 118554: 4.1232, 126466: 2.0256, 141693: 5.6303, 151496: 3.9948, 156678: 6.0789, 169961: 4.7724, 172634: 4.6385, 181500: 5.8484, 184109: 7.6318, 189683: 1.9945, 206410: 9.1181, 208258: 2.5911, 215252: 9.7112, 219056: 5.9879, 219797: 8.3762, 221047: 2.608, 227091: 5.4627, 262144: 219.0}), labels=SparseVector(6, {}))]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'cast'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-65801982ca10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDoubleType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstart_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'toxic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'severe_toxic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'obscene'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'threat'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'insult'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'identity_hate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDoubleType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m            \u001b[0;31m#,'severe_toxic','obscene','threat','insult','identity_hate'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1182\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'cast'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

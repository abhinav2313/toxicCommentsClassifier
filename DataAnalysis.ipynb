{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import RegexTokenizer, Tokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        comment_text|\n",
      "+--------------------+\n",
      "|Yo bitch Ja Rule ...|\n",
      "|== From RfC == \n",
      "\n",
      "...|\n",
      "|\" \n",
      "\n",
      " == Sources =...|\n",
      "|:If you have a lo...|\n",
      "|I don't anonymous...|\n",
      "|Thank you for und...|\n",
      "|Please do not add...|\n",
      "|:Dear god this si...|\n",
      "|\" \n",
      " Only a fool c...|\n",
      "|== Double Redirec...|\n",
      "|I think its crap ...|\n",
      "|\"::: Somebody wil...|\n",
      "|, 25 February 201...|\n",
      "|\" \n",
      "\n",
      " It says it r...|\n",
      "|\" \n",
      "\n",
      " == Before ad...|\n",
      "|==Current Positio...|\n",
      "|this other one fr...|\n",
      "|== Reason for ban...|\n",
      "|:: Wallamoose was...|\n",
      "||blocked]] from e...|\n",
      "|==Indefinitely bl...|\n",
      "|== Arabs are comm...|\n",
      "|Please stop. If y...|\n",
      "|== Energy  == \n",
      "\n",
      " ...|\n",
      "|:yeah, thanks for...|\n",
      "|MLM Software,NBFC...|\n",
      "|@RedSlash, cut it...|\n",
      "|=================...|\n",
      "|. \n",
      "\n",
      "           Je...|\n",
      "|:::If Ollie or ot...|\n",
      "|\" \n",
      " *Support Per ...|\n",
      "|Professors to the...|\n",
      "|:::::I have added...|\n",
      "|\" \n",
      "\n",
      " :Not sure wh...|\n",
      "|일이삼사오육칠팔구하고십이요 에헤...|\n",
      "|I've deleted the ...|\n",
      "|== Nation Radio -...|\n",
      "|\"\"\" (per your use...|\n",
      "|\" \n",
      "\n",
      " ==balance== ...|\n",
      "|\" \n",
      "\n",
      " *@EdJohnston...|\n",
      "|REDIRECT Talk:Mi ...|\n",
      "|\" \n",
      " I'm not convi...|\n",
      "|== Thanks for the...|\n",
      "|\" \n",
      "\n",
      " == Ref: SS P...|\n",
      "|\" \n",
      "\n",
      " Look, Gerry ...|\n",
      "|== September 20th...|\n",
      "|I'd never think I...|\n",
      "|But this is not t...|\n",
      "|DJ Robinson is ga...|\n",
      "|== Dracula's Gran...|\n",
      "|I have been perfe...|\n",
      "|*I agree with Bil...|\n",
      "|==Category:Italia...|\n",
      "|== Someday Never ...|\n",
      "|\", 5 December 201...|\n",
      "|\":I see that you ...|\n",
      "|I WILL BURN YOU T...|\n",
      "|== Hebrean-Judeo-...|\n",
      "|== Can you work y...|\n",
      "|:Fuck off, you an...|\n",
      "|    Puwersa ng Masa!|\n",
      "|\"== Quidam Softwa...|\n",
      "|\" \n",
      " :There are no...|\n",
      "|Her body is perfe...|\n",
      "|:::::I am simply ...|\n",
      "|REDIRECT Talk:Kem...|\n",
      "|\" \n",
      " :::::See abov...|\n",
      "|um, taking a shot...|\n",
      "|\" \n",
      " ::Use of \"\"as...|\n",
      "|See also . . . ht...|\n",
      "|== Hello == \n",
      "\n",
      " Fu...|\n",
      "|== Must be said  ...|\n",
      "|May 2010  \n",
      "  Plea...|\n",
      "|== BrandonYusofTo...|\n",
      "|\" August 2006 (UT...|\n",
      "|\" \n",
      " :That is ridi...|\n",
      "|How dare you vand...|\n",
      "|\"I moved this fro...|\n",
      "|knock it off you ...|\n",
      "|aapn bhtla aanand...|\n",
      "|\" \n",
      " *** Not via a...|\n",
      "|::No, he is an ar...|\n",
      "|== Continued Vand...|\n",
      "|\" \n",
      "\n",
      " ==Proornis==...|\n",
      "|::ICES could hard...|\n",
      "|*:That's not a ve...|\n",
      "|\":::If you email ...|\n",
      "|\" \n",
      "\n",
      " You wrote: \n",
      "...|\n",
      "|==Image copyright...|\n",
      "|:Thanks for the c...|\n",
      "|Can't figure out ...|\n",
      "|\" \n",
      "\n",
      " * You used t...|\n",
      "|::You're funny.  ...|\n",
      "|It might not have...|\n",
      "|Agree, but that's...|\n",
      "|\" \n",
      "\n",
      " == Main town...|\n",
      "|\" \n",
      "\n",
      "  my comments...|\n",
      "|\" \n",
      "\n",
      " == Halliday ...|\n",
      "|\" \n",
      " ::: That Step...|\n",
      "|Stone Sour sucks ...|\n",
      "+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName('tokenizer').getOrCreate()\n",
    "# Using directly pyspark is giving rubbish so creating pandas df and converting to pyspark dataframe\n",
    "sqlCtx = SQLContext(spark)\n",
    "# Pandas dataframe\n",
    "panda_df = pd.read_csv(\"test.csv\")\n",
    "# Converting pandas to pyspark\n",
    "pyspark_dataframe = sqlCtx.createDataFrame(panda_df)\n",
    "pyspark_dataframe.select(\"comment_text\").show(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+--------------------+\n",
      "|              id|        comment_text|      tokenized_text|\n",
      "+----------------+--------------------+--------------------+\n",
      "|00001cee341fdb12|Yo bitch Ja Rule ...|[yo, bitch, ja, r...|\n",
      "|0000247867823ef7|== From RfC == \n",
      "\n",
      "...|[==, from, rfc, =...|\n",
      "|00013b17ad220c46|\" \n",
      "\n",
      " == Sources =...|[\", , , , ==, sou...|\n",
      "|00017563c3f7919a|:If you have a lo...|[:if, you, have, ...|\n",
      "|00017695ad8997eb|I don't anonymous...|[i, don't, anonym...|\n",
      "|0001ea8717f6de06|Thank you for und...|[thank, you, for,...|\n",
      "|00024115d4cbde0f|Please do not add...|[please, do, not,...|\n",
      "|000247e83dcc1211|:Dear god this si...|[:dear, god, this...|\n",
      "|00025358d4737918|\" \n",
      " Only a fool c...|[\", , , only, a, ...|\n",
      "|00026d1092fe71cc|== Double Redirec...|[==, double, redi...|\n",
      "|0002eadc3b301559|I think its crap ...|[i, think, its, c...|\n",
      "|0002f87b16116a7f|\"::: Somebody wil...|[\":::, somebody, ...|\n",
      "|0003806b11932181|, 25 February 201...|[,, 25, february,...|\n",
      "|0003e1cccfd5a40a|\" \n",
      "\n",
      " It says it r...|[\", , , , it, say...|\n",
      "|00059ace3e3e9a53|\" \n",
      "\n",
      " == Before ad...|[\", , , , ==, bef...|\n",
      "|000634272d0d44eb|==Current Positio...|[==current, posit...|\n",
      "|000663aff0fffc80|this other one fr...|[this, other, one...|\n",
      "|000689dd34e20979|== Reason for ban...|[==, reason, for,...|\n",
      "|000834769115370c|:: Wallamoose was...|[::, wallamoose, ...|\n",
      "|000844b52dee5f3f||blocked]] from e...|[|blocked]], from...|\n",
      "+----------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the comments\n",
    "tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"tokenized_text\")\n",
    "tokenized = tokenizer.transform(pyspark_dataframe)\n",
    "tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/abhsharm/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        comment_text|\n",
      "+--------------------+\n",
      "|Yo bitch Ja Rule ...|\n",
      "|== From RfC == \n",
      "\n",
      "...|\n",
      "|\" \n",
      "\n",
      " == Sources =...|\n",
      "|:If you have a lo...|\n",
      "|I don't anonymous...|\n",
      "|Thank you for und...|\n",
      "|Please do not add...|\n",
      "|:Dear god this si...|\n",
      "|\" \n",
      " Only a fool c...|\n",
      "|== Double Redirec...|\n",
      "|I think its crap ...|\n",
      "|\"::: Somebody wil...|\n",
      "|, 25 February 201...|\n",
      "|\" \n",
      "\n",
      " It says it r...|\n",
      "|\" \n",
      "\n",
      " == Before ad...|\n",
      "|==Current Positio...|\n",
      "|this other one fr...|\n",
      "|== Reason for ban...|\n",
      "|:: Wallamoose was...|\n",
      "||blocked]] from e...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-66d16e3158fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcomments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"comment_text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "comments = pyspark_dataframe.select(\"comment_text\").show()\n",
    "for comment in comments:\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
